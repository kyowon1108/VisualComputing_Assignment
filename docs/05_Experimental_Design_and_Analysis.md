# 실험 설계와 성능 분석: 최적 결과를 위한 전략적 접근

## 목차
1. [촬영 조건 설계 전략](#촬영-조건-설계-전략)
2. [성능 분석 및 벤치마킹](#성능-분석-및-벤치마킹)
3. [실패 사례 및 한계 분석](#실패-사례-및-한계-분석)
4. [산업 응용 사례](#산업-응용-사례)

---

## 촬영 조건 설계 전략

### 히스토그램 평활화 최적 촬영 조건

#### 1. 어두운 실내 → 밝은 창가 시나리오

**촬영 설정:**
- 이미지 크기: 640x480 (4:3 비율 유지)
- 조명 조건: 한쪽은 창문 자연광, 반대쪽은 실내등 or 그림자
- 피사체: 텍스트가 포함된 문서나 책

**선정 이유:**
```
히스토그램 분포 특성:
- 어두운 영역 (0-80): 40-50% 집중
- 중간 영역 (81-170): 20-30% 분포
- 밝은 영역 (171-255): 10-20% 분포

YUV 처리 효과 극대화:
- Y 채널의 명확한 대비 개선
- U, V 채널의 색상 정보 보존 확인 가능
```

**예상 결과:**
- CDF 곡선에서 급격한 기울기 변화 관찰
- 어두운 디테일의 극적인 복원
- RGB 개별 처리 대비 자연스러운 색감 유지

#### 2. 역광 인물 사진

**촬영 설정:**
- 배경: 밝은 창문이나 하늘
- 인물: 실루엣에 가까운 어두운 상태
- 카메라 설정: 배경에 노출 맞춤

**선정 이유:**
```
극단적 명암비 조건:
- 배경 (200-255): 30-40%
- 인물 윤곽 (0-50): 40-50%
- 중간톤 (51-199): 10-20%

처리 방법별 차이점 극명:
- RGB 방법: 인물 색상 왜곡 심각
- YUV 방법: 자연스러운 인물 색감 유지
```

#### 3. 야간 도시 풍경

**촬영 설정:**
- 시간: 해질녘 또는 야간
- 구성: 가로등, 건물 조명, 어두운 하늘
- 초점: 전체적으로 어두우나 부분적 밝은 영역

**선정 이유:**
- 히스토그램의 저주파 집중 현상
- CLAHE와 일반 HE의 차이점 극명하게 드러남
- 노이즈 증폭 현상 관찰 가능

### Otsu Thresholding 최적 촬영 조건

#### 1. 그림자가 있는 문서

**촬영 설정:**
- 피사체: A4 용지에 인쇄된 텍스트
- 조명: 한쪽에서 비스듬히 조명하여 점진적 그림자 생성
- 배경: 단순한 책상 표면

**선정 이유:**
```
지역적 조명 변화:
- 밝은 영역 임계값: 180-200
- 어두운 영역 임계값: 100-120
- Global Otsu: 평균값 140-150 (부적절)

Local 방법의 우수성 입증:
- Block-based: 블록별 적응적 임계값
- Sliding Window: 부드러운 임계값 전환
```

#### 2. 오래된 책 페이지

**촬영 설정:**
- 피사체: 누렇게 변색된 책 페이지
- 조명: 불균등한 실내 조명
- 특징: 얼룩, 변색, 그림자 등 복합적 노이즈

**선정 이유:**
```
복잡한 배경 조건:
- 종이 변색으로 인한 배경값 불균일
- 잉크 번짐으로 인한 전경값 변화
- 주름과 그림자로 인한 지역적 명암 변화

3가지 방법 성능 차이 극명:
- Global: 대부분 실패
- Block-based: 일부 성공, 경계 불연속
- Sliding Window: 최적 결과
```

#### 3. 창문 실루엣

**촬영 설정:**
- 구성: 실내에서 밝은 창문을 배경으로 한 객체
- 명암비: 매우 높음 (배경 250+, 객체 30-)
- 중간톤: 거의 없는 이중 모드 히스토그램

**선정 이유:**
```
이상적인 Otsu 조건:
- 명확한 이중 모드 분포
- Inter-class variance 최대화 가능
- 모든 방법에서 유사한 성능 기대

Otsu 방법의 수학적 원리 검증:
- 이론적 최적점과 실제 결과 일치 확인
- Between-class variance 그래프 분석
```

### 640x480 해상도 최적화 전략

#### 해상도별 파라미터 조정

```python
# Block-based 최적 설정
block_sizes = {
    '640x480': (32, 32),    # 20x15 블록 = 300개 블록
    '320x240': (16, 16),    # 20x15 블록 = 300개 블록 (일관성 유지)
    '1280x960': (64, 64)    # 20x15 블록 = 300개 블록
}

# Sliding Window 최적 설정
window_configs = {
    '640x480': {'window_size': (32, 32), 'stride': 8},  # 75% 겹침
    '320x240': {'window_size': (16, 16), 'stride': 4},  # 75% 겹침 유지
    '1280x960': {'window_size': (64, 64), 'stride': 16} # 75% 겹침 유지
}
```

#### 종횡비 유지 전략

```python
def maintain_aspect_ratio(original_size, target_size=(640, 480)):
    """4:3 비율 유지하며 리사이징"""
    original_ratio = original_size[1] / original_size[0]  # width/height
    target_ratio = 4/3

    if original_ratio > target_ratio:
        # 원본이 더 넓음 - height 기준 조정
        new_height = 480
        new_width = int(480 * original_ratio)
        # 중앙 크롭으로 640x480 추출
    else:
        # 원본이 더 높음 - width 기준 조정
        new_width = 640
        new_height = int(640 / original_ratio)
        # 중앙 크롭으로 640x480 추출
```

---

## 성능 분석 및 벤치마킹

### 계산 복잡도 분석

#### 히스토그램 평활화 복잡도

```python
# 알고리즘별 시간 복잡도
complexities = {
    'Global HE': 'O(n + 256)',           # n: 픽셀 수, 히스토그램 계산 + CDF
    'CLAHE': 'O(n + t×256)',             # t: 타일 수 = (H/th)×(W/tw)
    'Color HE (YUV)': 'O(3n + 256)',     # 색공간 변환 + Y채널 HE
    'Color HE (RGB)': 'O(3n + 3×256)'   # 3채널 독립 처리
}

# 640x480 이미지 기준 연산량
image_pixels = 640 * 480  # 307,200 픽셀
tile_count_8x8 = (640//8) * (480//8)  # 6,000 타일
```

#### Otsu Thresholding 복잡도

```python
# 방법별 시간 복잡도
otsu_complexities = {
    'Global Otsu': 'O(n + 256²)',                    # 히스토그램 + 256회 variance 계산
    'Block-based': 'O(n + b×256²)',                  # b: 블록 수
    'Sliding Window': 'O(n×w + w×256²)',             # w: 윈도우 수, 중복 계산 포함
}

# 640x480 이미지 기준
block_count_32x32 = (640//32) * (480//32)  # 300 블록
window_count = ((640-32)//8 + 1) * ((480-32)//8 + 1)  # 4,617 윈도우
```

### 실제 성능 벤치마킹

#### 처리 시간 측정

```python
# src/performance_benchmark.py 구현 예시
import time
import numpy as np
from typing import Dict, List

def benchmark_he_methods(image: np.ndarray, iterations: int = 10) -> Dict[str, float]:
    """히스토그램 평활화 방법별 처리 시간 측정"""
    results = {}

    # Global HE
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = histogram_equalization_grayscale(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Global_HE'] = np.mean(times)

    # CLAHE 8x8
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = clahe_implementation(image, tile_size=(8, 8), show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['CLAHE_8x8'] = np.mean(times)

    return results

def benchmark_otsu_methods(image: np.ndarray, iterations: int = 10) -> Dict[str, float]:
    """Otsu 방법별 처리 시간 측정"""
    results = {}

    # Global Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = global_otsu_thresholding(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Global_Otsu'] = np.mean(times)

    # Block-based Local Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = local_otsu_block_based(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Block_Otsu'] = np.mean(times)

    # Sliding Window Local Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = local_otsu_sliding_window(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Sliding_Otsu'] = np.mean(times)

    return results
```

#### OpenCV 대비 성능 비교

```python
def compare_with_opencv(image: np.ndarray) -> Dict[str, Dict[str, float]]:
    """OpenCV 내장 함수와 성능 비교"""
    import cv2

    # 히스토그램 평활화 비교
    he_comparison = {}

    # Our implementation
    start = time.perf_counter()
    our_result = histogram_equalization_grayscale(image, show_process=False)
    our_time = time.perf_counter() - start

    # OpenCV implementation
    start = time.perf_counter()
    cv_result = cv2.equalizeHist(image)
    cv_time = time.perf_counter() - start

    he_comparison = {
        'our_implementation': our_time,
        'opencv': cv_time,
        'speed_ratio': our_time / cv_time,
        'result_difference': np.mean(np.abs(our_result[0] - cv_result))
    }

    # CLAHE 비교
    clahe_comparison = {}

    # Our CLAHE
    start = time.perf_counter()
    our_clahe = clahe_implementation(image, show_process=False)
    our_time = time.perf_counter() - start

    # OpenCV CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    start = time.perf_counter()
    cv_clahe = clahe.apply(image)
    cv_time = time.perf_counter() - start

    clahe_comparison = {
        'our_implementation': our_time,
        'opencv': cv_time,
        'speed_ratio': our_time / cv_time,
        'result_difference': np.mean(np.abs(our_clahe[0] - cv_clahe))
    }

    return {
        'histogram_equalization': he_comparison,
        'clahe': clahe_comparison
    }
```

### 메모리 사용량 분석

```python
import psutil
import os

def measure_memory_usage(func, *args, **kwargs):
    """함수 실행 중 메모리 사용량 측정"""
    process = psutil.Process(os.getpid())

    # 시작 메모리
    start_memory = process.memory_info().rss / 1024 / 1024  # MB

    # 함수 실행
    result = func(*args, **kwargs)

    # 종료 메모리
    end_memory = process.memory_info().rss / 1024 / 1024  # MB

    return result, end_memory - start_memory

# 사용 예시
image = np.random.randint(0, 256, (480, 640), dtype=np.uint8)

# Global Otsu 메모리 사용량
_, global_memory = measure_memory_usage(global_otsu_thresholding, image, False)

# Sliding Window 메모리 사용량
_, sliding_memory = measure_memory_usage(local_otsu_sliding_window, image, False)

print(f"Global Otsu: {global_memory:.2f} MB")
print(f"Sliding Window: {sliding_memory:.2f} MB")
```

### 정량적 품질 평가

#### 히스토그램 평활화 품질 지표

```python
def evaluate_he_quality(original: np.ndarray, enhanced: np.ndarray) -> Dict[str, float]:
    """히스토그램 평활화 품질 평가"""

    # 1. 엔트로피 증가량
    def calculate_entropy(image):
        hist, _ = compute_histogram(image)
        hist = hist / np.sum(hist)  # 정규화
        entropy = -np.sum(hist * np.log2(hist + 1e-10))
        return entropy

    original_entropy = calculate_entropy(original)
    enhanced_entropy = calculate_entropy(enhanced)

    # 2. 대비 개선도 (표준편차 증가율)
    contrast_improvement = np.std(enhanced) / np.std(original)

    # 3. 히스토그램 균등성 (Chi-square test)
    enhanced_hist, _ = compute_histogram(enhanced)
    expected = np.full(256, enhanced.size / 256)  # 균등분포 기댓값
    chi_square = np.sum((enhanced_hist - expected)**2 / expected)

    # 4. 동적 범위 활용도
    dynamic_range = (np.max(enhanced) - np.min(enhanced)) / 255.0

    return {
        'entropy_gain': enhanced_entropy - original_entropy,
        'contrast_improvement': contrast_improvement,
        'uniformity_score': 1.0 / (1.0 + chi_square / 1000),  # 정규화
        'dynamic_range_usage': dynamic_range
    }
```

#### Otsu Thresholding 품질 지표

```python
def evaluate_otsu_quality(image: np.ndarray, binary_result: np.ndarray,
                         threshold_map: np.ndarray = None) -> Dict[str, float]:
    """Otsu Thresholding 품질 평가"""

    # 1. Inter-class variance (클수록 좋음)
    hist, _ = compute_histogram(image)
    if threshold_map is None:
        # Global threshold
        threshold = np.mean(threshold_map) if threshold_map is not None else 127
        _, calc_info = calculate_otsu_threshold(hist)
        inter_class_var = calc_info['max_inter_class_variance']
    else:
        # Local threshold - 평균 inter-class variance
        inter_class_var = np.mean([calculate_inter_class_variance(image, t)
                                  for t in np.unique(threshold_map)])

    # 2. 연결성 지표 (Connected Components)
    num_labels, labels = cv2.connectedComponents(binary_result.astype(np.uint8))
    connectivity_score = 1.0 / (1.0 + num_labels / 100)  # 정규화

    # 3. 엣지 보존 정도
    def edge_preservation_score(original, binary):
        # Sobel edge detection
        edges_original = cv2.Sobel(original, cv2.CV_64F, 1, 1, ksize=3)
        edges_binary = cv2.Sobel(binary, cv2.CV_64F, 1, 1, ksize=3)

        # 상관계수 계산
        correlation = np.corrcoef(edges_original.flatten(),
                                edges_binary.flatten())[0,1]
        return max(0, correlation)  # 음수 제거

    edge_score = edge_preservation_score(image, binary_result)

    # 4. 노이즈 레벨 (작을수록 좋음)
    noise_level = np.std(binary_result - cv2.medianBlur(binary_result, 5))

    return {
        'inter_class_variance': inter_class_var,
        'connectivity_score': connectivity_score,
        'edge_preservation': edge_score,
        'noise_level': noise_level
    }
```

---

## 실패 사례 및 한계 분석

### 히스토그램 평활화 실패 사례

#### 1. 극단적 저조도 이미지

**실패 조건:**
- 대부분 픽셀이 0-30 범위에 집중 (85% 이상)
- 유효 정보가 매우 적은 경우

**실패 원인:**
```python
# 문제점 분석
hist, _ = compute_histogram(very_dark_image)
valid_info_ratio = np.sum(hist[30:]) / np.sum(hist)

if valid_info_ratio < 0.15:
    print("경고: 유효 정보 부족으로 HE 효과 제한적")

# CDF 분석
cdf = calculate_cdf(hist)
steep_slope = np.max(np.diff(cdf[:50]))  # 초기 50구간 기울기

if steep_slope > 0.8:
    print("경고: 급격한 매핑으로 인한 계단 현상 발생 가능")
```

**해결 방안:**
- 감마 보정 전처리 적용
- CLAHE의 clip_limit 조정 (0.5-1.0)
- 적응적 전처리 적용

#### 2. 포화된 밝은 이미지

**실패 조건:**
- 대부분 픽셀이 220-255 범위에 집중
- 오버 익스포저 상태

**문제점:**
```python
# 포화 영역 분석
saturated_ratio = np.sum(image >= 250) / image.size

if saturated_ratio > 0.3:
    print("경고: 포화 영역 과다로 디테일 복원 불가")

# 히스토그램 분포 분석
hist, _ = compute_histogram(image)
high_intensity_ratio = np.sum(hist[200:]) / np.sum(hist)

if high_intensity_ratio > 0.7:
    print("경고: 히스토그램 평활화 효과 미미")
```

#### 3. 컬러 이미지에서 RGB 개별 처리 문제

**색상 왜곡 사례:**
```python
# RGB 개별 처리 시 색상 변화 측정
def measure_color_distortion(original_rgb, processed_rgb):
    # HSV 색공간에서 Hue 변화량 측정
    original_hsv = cv2.cvtColor(original_rgb, cv2.COLOR_RGB2HSV)
    processed_hsv = cv2.cvtColor(processed_rgb, cv2.COLOR_RGB2HSV)

    hue_diff = np.abs(original_hsv[:,:,0].astype(float) -
                     processed_hsv[:,:,0].astype(float))

    # Hue는 순환적이므로 180도 이상 차이는 보정
    hue_diff = np.minimum(hue_diff, 360 - hue_diff)

    mean_hue_shift = np.mean(hue_diff)
    return mean_hue_shift

# YUV vs RGB 처리 비교
yuv_result, _ = histogram_equalization_color(image, method='yuv')
rgb_result, _ = histogram_equalization_color(image, method='rgb')

yuv_distortion = measure_color_distortion(image, yuv_result)
rgb_distortion = measure_color_distortion(image, rgb_result)

print(f"YUV 방법 색상 변화: {yuv_distortion:.2f}도")
print(f"RGB 방법 색상 변화: {rgb_distortion:.2f}도")
```

### Otsu Thresholding 실패 사례

#### 1. 단일 모드 히스토그램

**실패 조건:**
- 전경과 배경의 분리가 불명확
- 히스토그램이 단봉 분포

**분석 방법:**
```python
def analyze_histogram_modality(image):
    """히스토그램 모드 분석"""
    hist, _ = compute_histogram(image)

    # 스무딩된 히스토그램으로 피크 찾기
    from scipy.signal import find_peaks
    smoothed_hist = np.convolve(hist, np.ones(5)/5, mode='same')
    peaks, _ = find_peaks(smoothed_hist, height=np.max(smoothed_hist)*0.1)

    if len(peaks) < 2:
        print("경고: 단일 모드 히스토그램 - Otsu 방법 부적합")
        return False

    # 두 주요 피크 간 valley 깊이 확인
    valley_depth = np.min(smoothed_hist[peaks[0]:peaks[1]])
    peak_height = np.mean([smoothed_hist[peaks[0]], smoothed_hist[peaks[1]]])

    if valley_depth / peak_height > 0.5:
        print("경고: 얕은 valley - 분리 성능 제한적")
        return False

    return True
```

#### 2. 극단적 불균등 조명

**실패 조건:**
- 한쪽 끝이 매우 밝고 다른 쪽이 매우 어두움
- 점진적 변화로 인한 지역별 최적 임계값 큰 차이

**문제점 분석:**
```python
def analyze_illumination_gradient(image):
    """조명 기울기 분석"""
    # 이미지를 격자로 나누어 평균 밝기 분석
    h, w = image.shape
    grid_h, grid_w = h//4, w//4

    brightness_map = np.zeros((4, 4))
    for i in range(4):
        for j in range(4):
            region = image[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]
            brightness_map[i, j] = np.mean(region)

    # 최대 밝기 차이 계산
    max_diff = np.max(brightness_map) - np.min(brightness_map)

    if max_diff > 100:
        print(f"경고: 조명 불균등 심각 (차이: {max_diff:.1f})")
        print("권장: Local Otsu 방법 사용")
        return True

    return False
```

#### 3. Block-based의 경계 불연속성

**문제 시각화:**
```python
def visualize_block_discontinuity(image, block_size=(32, 32)):
    """블록 경계 불연속성 시각화"""
    # Block-based 처리
    result, info = local_otsu_block_based(image, block_size=block_size, show_process=False)
    threshold_map = info['threshold_map']

    # 임계값 차이 맵 생성
    h, w = threshold_map.shape
    bh, bw = block_size

    diff_map = np.zeros_like(threshold_map)

    # 블록 경계에서 임계값 차이 계산
    for i in range(bh, h, bh):
        diff_map[i-1:i+1, :] = np.abs(threshold_map[i-2, :] - threshold_map[i+1, :])

    for j in range(bw, w, bw):
        diff_map[:, j-1:j+1] = np.abs(threshold_map[:, j-2] - threshold_map[:, j+1])

    # 불연속성 심각도 평가
    discontinuity_score = np.mean(diff_map[diff_map > 0])

    if discontinuity_score > 30:
        print(f"경고: 블록 경계 불연속성 심각 (점수: {discontinuity_score:.1f})")
        print("권장: Sliding Window 방법 또는 블록 크기 축소")

    return diff_map, discontinuity_score
```

### 한계점 및 개선 방향

#### 1. 실시간 처리 한계

**현재 한계:**
- Sliding Window 방법의 높은 계산 복잡도
- 640x480 이미지 처리 시간: 0.5-2초

**개선 방안:**
```python
# 병렬 처리 최적화
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor

def parallel_sliding_window(image, window_size, stride, num_workers=4):
    """병렬 처리를 이용한 Sliding Window 최적화"""
    h, w = image.shape
    wh, ww = window_size

    # 작업 분할
    work_regions = []
    region_h = h // num_workers

    for i in range(num_workers):
        start_row = i * region_h
        end_row = (i + 1) * region_h if i < num_workers - 1 else h
        work_regions.append((start_row, end_row))

    # 병렬 실행
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for start_row, end_row in work_regions:
            region = image[start_row:end_row, :]
            future = executor.submit(process_sliding_window_region,
                                   region, window_size, stride)
            futures.append(future)

        results = [future.result() for future in futures]

    # 결과 병합
    return merge_results(results)
```

#### 2. 메모리 사용량 최적화

**현재 문제:**
- Sliding Window에서 중복 히스토그램 계산
- 임계값 맵 저장으로 인한 메모리 사용량 증가

**개선 방안:**
```python
def memory_efficient_sliding_window(image, window_size, stride):
    """메모리 효율적인 Sliding Window 구현"""
    h, w = image.shape
    wh, ww = window_size

    # 결과 이미지만 저장, 임계값 맵 생략
    result = np.zeros_like(image)

    # 스트리밍 방식으로 처리
    for i in range(0, h - wh + 1, stride):
        for j in range(0, w - ww + 1, stride):
            # 윈도우 영역 처리
            window = image[i:i+wh, j:j+ww]
            threshold = calculate_local_threshold(window)

            # 결과에 직접 적용 (중간 저장소 불필요)
            center_i = i + wh//2
            center_j = j + ww//2
            result[center_i-stride//2:center_i+stride//2,
                   center_j-stride//2:center_j+stride//2] = \
                apply_threshold(image[center_i-stride//2:center_i+stride//2,
                                    center_j-stride//2:center_j+stride//2],
                              threshold)

    return result
```

---

## 산업 응용 사례

### 문서 디지털화 시스템

#### 응용 분야
- 도서관 고문서 디지털화
- 법무 문서 아카이빙
- 의료 차트 전산화

#### 기술적 요구사항
```python
class DocumentDigitizer:
    """문서 디지털화 시스템"""

    def __init__(self):
        self.he_config = {
            'method': 'yuv',
            'clahe_params': {'clip_limit': 1.5, 'tile_size': (16, 16)}
        }
        self.otsu_config = {
            'method': 'sliding_window',
            'window_size': (24, 24),
            'stride': 6
        }

    def process_document(self, image_path: str) -> Dict[str, np.ndarray]:
        """문서 이미지 전처리 파이프라인"""
        # 1. 이미지 로드 및 전처리
        image = self.load_and_preprocess(image_path)

        # 2. 조명 보정 (히스토그램 평활화)
        enhanced_image = self.enhance_illumination(image)

        # 3. 이진화 (Otsu Thresholding)
        binary_image = self.binarize_document(enhanced_image)

        # 4. 후처리 (노이즈 제거, 기울기 보정)
        final_image = self.post_process(binary_image)

        return {
            'original': image,
            'enhanced': enhanced_image,
            'binary': binary_image,
            'final': final_image
        }

    def enhance_illumination(self, image: np.ndarray) -> np.ndarray:
        """조명 불균등 보정"""
        # 조명 불균등 정도 자동 감지
        illumination_variance = self.analyze_illumination_uniformity(image)

        if illumination_variance > 50:
            # 심한 불균등 → CLAHE 적용
            result, _ = clahe_implementation(
                image,
                clip_limit=self.he_config['clahe_params']['clip_limit'],
                tile_size=self.he_config['clahe_params']['tile_size'],
                show_process=False
            )
        else:
            # 경미한 불균등 → 일반 HE 적용
            result, _ = histogram_equalization_grayscale(image, show_process=False)

        return result

    def binarize_document(self, image: np.ndarray) -> np.ndarray:
        """문서 이진화"""
        # 히스토그램 모드 분석으로 방법 선택
        is_bimodal = self.analyze_histogram_modality(image)

        if is_bimodal:
            # 명확한 이중 모드 → Global Otsu
            result, _ = global_otsu_thresholding(image, show_process=False)
        else:
            # 복잡한 분포 → Local Otsu
            result, _ = local_otsu_sliding_window(
                image,
                window_size=self.otsu_config['window_size'],
                stride=self.otsu_config['stride'],
                show_process=False
            )

        return result
```

#### 성능 지표
- 처리 속도: 640x480 문서당 2-5초
- OCR 정확도 향상: 15-25%
- 파일 크기 감소: 40-60% (이진화 효과)

### 의료 영상 처리

#### 응용 분야
- X-ray 이미지 대비 개선
- 초음파 영상 선명도 향상
- 내시경 영상 전처리

#### X-ray 이미지 처리 시스템
```python
class MedicalImageProcessor:
    """의료 영상 처리 시스템"""

    def __init__(self):
        self.xray_config = {
            'clahe_clip_limit': 3.0,  # 의료 영상은 높은 대비 필요
            'tile_size': (8, 8),
            'gamma_correction': 0.8   # 감마 보정으로 중간톤 강조
        }

    def enhance_xray(self, xray_image: np.ndarray) -> Dict[str, np.ndarray]:
        """X-ray 영상 대비 개선"""
        # 1. 감마 보정으로 중간톤 영역 강조
        gamma_corrected = self.apply_gamma_correction(
            xray_image,
            gamma=self.xray_config['gamma_correction']
        )

        # 2. CLAHE로 지역적 대비 개선
        clahe_enhanced, _ = clahe_implementation(
            gamma_corrected,
            clip_limit=self.xray_config['clahe_clip_limit'],
            tile_size=self.xray_config['tile_size'],
            show_process=False
        )

        # 3. 노이즈 감소를 위한 적응적 필터링
        denoised = self.adaptive_denoising(clahe_enhanced)

        return {
            'original': xray_image,
            'gamma_corrected': gamma_corrected,
            'clahe_enhanced': clahe_enhanced,
            'final': denoised
        }

    def apply_gamma_correction(self, image: np.ndarray, gamma: float) -> np.ndarray:
        """감마 보정 적용"""
        # 룩업 테이블 생성
        inv_gamma = 1.0 / gamma
        lut = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(np.uint8)

        # 룩업 테이블 적용
        return lut[image]
```

### 보안 감시 시스템

#### 응용 분야
- 야간 감시 카메라 영상 개선
- 차량 번호판 인식 전처리
- 얼굴 인식 시스템 전처리

#### 실시간 영상 처리 시스템
```python
class SecurityVisionSystem:
    """보안 감시 영상 처리 시스템"""

    def __init__(self):
        self.day_config = {
            'he_method': 'global',
            'otsu_method': 'block_based'
        }
        self.night_config = {
            'he_method': 'clahe',
            'clahe_params': {'clip_limit': 4.0, 'tile_size': (16, 16)},
            'otsu_method': 'sliding_window'
        }

    def process_surveillance_frame(self, frame: np.ndarray,
                                 is_night_mode: bool = False) -> Dict[str, np.ndarray]:
        """감시 영상 프레임 처리"""
        config = self.night_config if is_night_mode else self.day_config

        # 1. 조명 조건에 따른 적응적 대비 개선
        if config['he_method'] == 'clahe':
            enhanced, _ = clahe_implementation(
                frame,
                clip_limit=config['clahe_params']['clip_limit'],
                tile_size=config['clahe_params']['tile_size'],
                show_process=False
            )
        else:
            enhanced, _ = histogram_equalization_grayscale(frame, show_process=False)

        # 2. 객체 분할을 위한 이진화
        if config['otsu_method'] == 'sliding_window':
            binary, _ = local_otsu_sliding_window(enhanced, show_process=False)
        else:
            binary, _ = local_otsu_block_based(enhanced, show_process=False)

        # 3. 모션 감지용 전처리
        motion_ready = self.prepare_for_motion_detection(enhanced)

        return {
            'enhanced': enhanced,
            'binary': binary,
            'motion_ready': motion_ready
        }

    def prepare_for_motion_detection(self, image: np.ndarray) -> np.ndarray:
        """모션 감지를 위한 전처리"""
        # 가우시안 블러로 노이즈 감소
        blurred = cv2.GaussianBlur(image, (5, 5), 0)

        # 적응적 임계값으로 배경 분리
        adaptive_thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 11, 2
        )

        return adaptive_thresh
```

### 산업 자동화 비전 시스템

#### 응용 분야
- 제품 품질 검사
- 바코드/QR코드 인식
- 로봇 비전 시스템

#### 제품 검사 시스템
```python
class IndustrialVisionInspector:
    """산업용 비전 검사 시스템"""

    def __init__(self):
        self.inspection_config = {
            'he_clip_limit': 2.5,
            'tile_size': (12, 12),
            'window_size': (20, 20),
            'stride': 5
        }

    def inspect_product(self, product_image: np.ndarray) -> Dict[str, any]:
        """제품 검사 수행"""
        # 1. 조명 정규화
        normalized = self.normalize_illumination(product_image)

        # 2. 결함 감지를 위한 이진화
        defect_map = self.detect_defects(normalized)

        # 3. 치수 측정을 위한 엣지 검출
        edges = self.extract_measurement_edges(normalized)

        # 4. 검사 결과 분석
        inspection_result = self.analyze_inspection_results(defect_map, edges)

        return {
            'normalized_image': normalized,
            'defect_map': defect_map,
            'measurement_edges': edges,
            'pass_fail': inspection_result['pass_fail'],
            'defect_count': inspection_result['defect_count'],
            'measurements': inspection_result['measurements']
        }

    def normalize_illumination(self, image: np.ndarray) -> np.ndarray:
        """조명 정규화 (공장 환경의 불균등 조명 보정)"""
        # CLAHE로 지역적 조명 변화 보정
        normalized, _ = clahe_implementation(
            image,
            clip_limit=self.inspection_config['he_clip_limit'],
            tile_size=self.inspection_config['tile_size'],
            show_process=False
        )

        return normalized

    def detect_defects(self, image: np.ndarray) -> np.ndarray:
        """결함 감지용 이진화"""
        # 높은 해상도의 Local Otsu로 미세 결함 감지
        defect_binary, _ = local_otsu_sliding_window(
            image,
            window_size=self.inspection_config['window_size'],
            stride=self.inspection_config['stride'],
            show_process=False
        )

        # 형태학적 연산으로 노이즈 제거
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        cleaned = cv2.morphologyEx(defect_binary, cv2.MORPH_OPEN, kernel)

        return cleaned
```

### 포팅 및 확장 가능성

#### C++ 포팅 고려사항
```cpp
// C++17 구현 예시 (핵심 부분)
class HistogramEqualizer {
private:
    std::vector<uint32_t> histogram_;
    std::vector<double> cdf_;

public:
    cv::Mat equalizeHistogram(const cv::Mat& input) {
        // 히스토그램 계산
        calculateHistogram(input);

        // CDF 계산
        calculateCDF();

        // 룩업 테이블 생성 및 적용
        std::vector<uint8_t> lut(256);
        for (int i = 0; i < 256; ++i) {
            lut[i] = static_cast<uint8_t>(255.0 * cdf_[i]);
        }

        cv::Mat output;
        cv::LUT(input, cv::Mat(lut), output);

        return output;
    }

private:
    void calculateHistogram(const cv::Mat& image) {
        histogram_.assign(256, 0);

        // OpenMP를 이용한 병렬화
        #pragma omp parallel for
        for (int i = 0; i < image.rows; ++i) {
            const uint8_t* row = image.ptr<uint8_t>(i);
            for (int j = 0; j < image.cols; ++j) {
                #pragma omp atomic
                ++histogram_[row[j]];
            }
        }
    }
};
```

#### CUDA GPU 가속 가능성
```cuda
// CUDA 커널 예시
__global__ void histogramEqualizationKernel(
    const uint8_t* input,
    uint8_t* output,
    const uint8_t* lut,
    int width,
    int height) {

    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_pixels = width * height;

    if (idx < total_pixels) {
        output[idx] = lut[input[idx]];
    }
}

// 호스트 코드
void cudaHistogramEqualization(
    const cv::Mat& input,
    cv::Mat& output) {

    // GPU 메모리 할당
    uint8_t* d_input, * d_output, * d_lut;

    // 히스토그램 계산 (GPU)
    computeHistogramCuda(d_input, d_histogram);

    // CDF 계산 (GPU)
    computeCDFCuda(d_histogram, d_cdf);

    // 룩업 테이블 생성 (GPU)
    generateLUTCuda(d_cdf, d_lut);

    // 이미지 변환 (GPU)
    dim3 block(256);
    dim3 grid((input.total() + block.x - 1) / block.x);

    histogramEqualizationKernel<<<grid, block>>>(
        d_input, d_output, d_lut,
        input.cols, input.rows
    );

    // 결과 복사
    cudaMemcpy(output.data, d_output,
               input.total(), cudaMemcpyDeviceToHost);
}
```

