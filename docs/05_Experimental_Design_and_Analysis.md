# ì‹¤í—˜ ì„¤ê³„ì™€ ì„±ëŠ¥ ë¶„ì„: ìµœì  ê²°ê³¼ë¥¼ ìœ„í•œ ì „ëµì  ì ‘ê·¼

## ëª©ì°¨
1. [ì´¬ì˜ ì¡°ê±´ ì„¤ê³„ ì „ëµ](#ì´¬ì˜-ì¡°ê±´-ì„¤ê³„-ì „ëµ)
2. [ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí‚¹](#ì„±ëŠ¥-ë¶„ì„-ë°-ë²¤ì¹˜ë§ˆí‚¹)
3. [ì‹¤íŒ¨ ì‚¬ë¡€ ë° í•œê³„ ë¶„ì„](#ì‹¤íŒ¨-ì‚¬ë¡€-ë°-í•œê³„-ë¶„ì„)
   - [ğŸ†• ë¸”ë¡ ê²½ê³„ ì•„í‹°íŒ©íŠ¸ í•´ê²°ì±…](#ë¸”ë¡-ê²½ê³„-ì•„í‹°íŒ©íŠ¸-í•´ê²°ì±…)
4. [ì‚°ì—… ì‘ìš© ì‚¬ë¡€](#ì‚°ì—…-ì‘ìš©-ì‚¬ë¡€)

---

## ì´¬ì˜ ì¡°ê±´ ì„¤ê³„ ì „ëµ

### íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ìµœì  ì´¬ì˜ ì¡°ê±´

#### 1. ì–´ë‘ìš´ ì‹¤ë‚´ â†’ ë°ì€ ì°½ê°€ ì‹œë‚˜ë¦¬ì˜¤

**ì´¬ì˜ ì„¤ì •:**
- ì´ë¯¸ì§€ í¬ê¸°: 640x480 (4:3 ë¹„ìœ¨ ìœ ì§€)
- ì¡°ëª… ì¡°ê±´: í•œìª½ì€ ì°½ë¬¸ ìì—°ê´‘, ë°˜ëŒ€ìª½ì€ ì‹¤ë‚´ë“± or ê·¸ë¦¼ì
- í”¼ì‚¬ì²´: í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ë¬¸ì„œë‚˜ ì±…

**ì„ ì • ì´ìœ :**
```
íˆìŠ¤í† ê·¸ë¨ ë¶„í¬ íŠ¹ì„±:
- ì–´ë‘ìš´ ì˜ì—­ (0-80): 40-50% ì§‘ì¤‘
- ì¤‘ê°„ ì˜ì—­ (81-170): 20-30% ë¶„í¬
- ë°ì€ ì˜ì—­ (171-255): 10-20% ë¶„í¬

YUV ì²˜ë¦¬ íš¨ê³¼ ê·¹ëŒ€í™”:
- Y ì±„ë„ì˜ ëª…í™•í•œ ëŒ€ë¹„ ê°œì„ 
- U, V ì±„ë„ì˜ ìƒ‰ìƒ ì •ë³´ ë³´ì¡´ í™•ì¸ ê°€ëŠ¥
```

**ì˜ˆìƒ ê²°ê³¼:**
- CDF ê³¡ì„ ì—ì„œ ê¸‰ê²©í•œ ê¸°ìš¸ê¸° ë³€í™” ê´€ì°°
- ì–´ë‘ìš´ ë””í…Œì¼ì˜ ê·¹ì ì¸ ë³µì›
- RGB ê°œë³„ ì²˜ë¦¬ ëŒ€ë¹„ ìì—°ìŠ¤ëŸ¬ìš´ ìƒ‰ê° ìœ ì§€

#### 2. ì—­ê´‘ ì¸ë¬¼ ì‚¬ì§„

**ì´¬ì˜ ì„¤ì •:**
- ë°°ê²½: ë°ì€ ì°½ë¬¸ì´ë‚˜ í•˜ëŠ˜
- ì¸ë¬¼: ì‹¤ë£¨ì—£ì— ê°€ê¹Œìš´ ì–´ë‘ìš´ ìƒíƒœ
- ì¹´ë©”ë¼ ì„¤ì •: ë°°ê²½ì— ë…¸ì¶œ ë§ì¶¤

**ì„ ì • ì´ìœ :**
```
ê·¹ë‹¨ì  ëª…ì•”ë¹„ ì¡°ê±´:
- ë°°ê²½ (200-255): 30-40%
- ì¸ë¬¼ ìœ¤ê³½ (0-50): 40-50%
- ì¤‘ê°„í†¤ (51-199): 10-20%

ì²˜ë¦¬ ë°©ë²•ë³„ ì°¨ì´ì  ê·¹ëª…:
- RGB ë°©ë²•: ì¸ë¬¼ ìƒ‰ìƒ ì™œê³¡ ì‹¬ê°
- YUV ë°©ë²•: ìì—°ìŠ¤ëŸ¬ìš´ ì¸ë¬¼ ìƒ‰ê° ìœ ì§€
```

#### 3. ì•¼ê°„ ë„ì‹œ í’ê²½

**ì´¬ì˜ ì„¤ì •:**
- ì‹œê°„: í•´ì§ˆë…˜ ë˜ëŠ” ì•¼ê°„
- êµ¬ì„±: ê°€ë¡œë“±, ê±´ë¬¼ ì¡°ëª…, ì–´ë‘ìš´ í•˜ëŠ˜
- ì´ˆì : ì „ì²´ì ìœ¼ë¡œ ì–´ë‘ìš°ë‚˜ ë¶€ë¶„ì  ë°ì€ ì˜ì—­

**ì„ ì • ì´ìœ :**
- íˆìŠ¤í† ê·¸ë¨ì˜ ì €ì£¼íŒŒ ì§‘ì¤‘ í˜„ìƒ
- CLAHEì™€ ì¼ë°˜ HEì˜ ì°¨ì´ì  ê·¹ëª…í•˜ê²Œ ë“œëŸ¬ë‚¨
- ë…¸ì´ì¦ˆ ì¦í­ í˜„ìƒ ê´€ì°° ê°€ëŠ¥

### Otsu Thresholding ìµœì  ì´¬ì˜ ì¡°ê±´

#### 1. ê·¸ë¦¼ìê°€ ìˆëŠ” ë¬¸ì„œ

**ì´¬ì˜ ì„¤ì •:**
- í”¼ì‚¬ì²´: A4 ìš©ì§€ì— ì¸ì‡„ëœ í…ìŠ¤íŠ¸
- ì¡°ëª…: í•œìª½ì—ì„œ ë¹„ìŠ¤ë“¬íˆ ì¡°ëª…í•˜ì—¬ ì ì§„ì  ê·¸ë¦¼ì ìƒì„±
- ë°°ê²½: ë‹¨ìˆœí•œ ì±…ìƒ í‘œë©´

**ì„ ì • ì´ìœ :**
```
ì§€ì—­ì  ì¡°ëª… ë³€í™”:
- ë°ì€ ì˜ì—­ ì„ê³„ê°’: 180-200
- ì–´ë‘ìš´ ì˜ì—­ ì„ê³„ê°’: 100-120
- Global Otsu: í‰ê· ê°’ 140-150 (ë¶€ì ì ˆ)

Local ë°©ë²•ì˜ ìš°ìˆ˜ì„± ì…ì¦:
- Block-based: ë¸”ë¡ë³„ ì ì‘ì  ì„ê³„ê°’
- Sliding Window: ë¶€ë“œëŸ¬ìš´ ì„ê³„ê°’ ì „í™˜
```

#### 2. ì˜¤ë˜ëœ ì±… í˜ì´ì§€

**ì´¬ì˜ ì„¤ì •:**
- í”¼ì‚¬ì²´: ëˆ„ë ‡ê²Œ ë³€ìƒ‰ëœ ì±… í˜ì´ì§€
- ì¡°ëª…: ë¶ˆê· ë“±í•œ ì‹¤ë‚´ ì¡°ëª…
- íŠ¹ì§•: ì–¼ë£©, ë³€ìƒ‰, ê·¸ë¦¼ì ë“± ë³µí•©ì  ë…¸ì´ì¦ˆ

**ì„ ì • ì´ìœ :**
```
ë³µì¡í•œ ë°°ê²½ ì¡°ê±´:
- ì¢…ì´ ë³€ìƒ‰ìœ¼ë¡œ ì¸í•œ ë°°ê²½ê°’ ë¶ˆê· ì¼
- ì‰í¬ ë²ˆì§ìœ¼ë¡œ ì¸í•œ ì „ê²½ê°’ ë³€í™”
- ì£¼ë¦„ê³¼ ê·¸ë¦¼ìë¡œ ì¸í•œ ì§€ì—­ì  ëª…ì•” ë³€í™”

3ê°€ì§€ ë°©ë²• ì„±ëŠ¥ ì°¨ì´ ê·¹ëª…:
- Global: ëŒ€ë¶€ë¶„ ì‹¤íŒ¨
- Block-based: ì¼ë¶€ ì„±ê³µ, ê²½ê³„ ë¶ˆì—°ì†
- Sliding Window: ìµœì  ê²°ê³¼
```

#### 3. ì°½ë¬¸ ì‹¤ë£¨ì—£

**ì´¬ì˜ ì„¤ì •:**
- êµ¬ì„±: ì‹¤ë‚´ì—ì„œ ë°ì€ ì°½ë¬¸ì„ ë°°ê²½ìœ¼ë¡œ í•œ ê°ì²´
- ëª…ì•”ë¹„: ë§¤ìš° ë†’ìŒ (ë°°ê²½ 250+, ê°ì²´ 30-)
- ì¤‘ê°„í†¤: ê±°ì˜ ì—†ëŠ” ì´ì¤‘ ëª¨ë“œ íˆìŠ¤í† ê·¸ë¨

**ì„ ì • ì´ìœ :**
```
ì´ìƒì ì¸ Otsu ì¡°ê±´:
- ëª…í™•í•œ ì´ì¤‘ ëª¨ë“œ ë¶„í¬
- Inter-class variance ìµœëŒ€í™” ê°€ëŠ¥
- ëª¨ë“  ë°©ë²•ì—ì„œ ìœ ì‚¬í•œ ì„±ëŠ¥ ê¸°ëŒ€

Otsu ë°©ë²•ì˜ ìˆ˜í•™ì  ì›ë¦¬ ê²€ì¦:
- ì´ë¡ ì  ìµœì ì ê³¼ ì‹¤ì œ ê²°ê³¼ ì¼ì¹˜ í™•ì¸
- Between-class variance ê·¸ë˜í”„ ë¶„ì„
```

### 640x480 í•´ìƒë„ ìµœì í™” ì „ëµ

#### í•´ìƒë„ë³„ íŒŒë¼ë¯¸í„° ì¡°ì •

```python
# Block-based ìµœì  ì„¤ì •
block_sizes = {
    '640x480': (32, 32),    # 20x15 ë¸”ë¡ = 300ê°œ ë¸”ë¡
    '320x240': (16, 16),    # 20x15 ë¸”ë¡ = 300ê°œ ë¸”ë¡ (ì¼ê´€ì„± ìœ ì§€)
    '1280x960': (64, 64)    # 20x15 ë¸”ë¡ = 300ê°œ ë¸”ë¡
}

# Sliding Window ìµœì  ì„¤ì •
window_configs = {
    '640x480': {'window_size': (32, 32), 'stride': 8},  # 75% ê²¹ì¹¨
    '320x240': {'window_size': (16, 16), 'stride': 4},  # 75% ê²¹ì¹¨ ìœ ì§€
    '1280x960': {'window_size': (64, 64), 'stride': 16} # 75% ê²¹ì¹¨ ìœ ì§€
}
```

#### ì¢…íš¡ë¹„ ìœ ì§€ ì „ëµ

```python
def maintain_aspect_ratio(original_size, target_size=(640, 480)):
    """4:3 ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì§•"""
    original_ratio = original_size[1] / original_size[0]  # width/height
    target_ratio = 4/3

    if original_ratio > target_ratio:
        # ì›ë³¸ì´ ë” ë„“ìŒ - height ê¸°ì¤€ ì¡°ì •
        new_height = 480
        new_width = int(480 * original_ratio)
        # ì¤‘ì•™ í¬ë¡­ìœ¼ë¡œ 640x480 ì¶”ì¶œ
    else:
        # ì›ë³¸ì´ ë” ë†’ìŒ - width ê¸°ì¤€ ì¡°ì •
        new_width = 640
        new_height = int(640 / original_ratio)
        # ì¤‘ì•™ í¬ë¡­ìœ¼ë¡œ 640x480 ì¶”ì¶œ
```

---

## ì„±ëŠ¥ ë¶„ì„ ë° ë²¤ì¹˜ë§ˆí‚¹

### ê³„ì‚° ë³µì¡ë„ ë¶„ì„

#### íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ë³µì¡ë„

```python
# ì•Œê³ ë¦¬ì¦˜ë³„ ì‹œê°„ ë³µì¡ë„
complexities = {
    'Global HE': 'O(n + 256)',           # n: í”½ì…€ ìˆ˜, íˆìŠ¤í† ê·¸ë¨ ê³„ì‚° + CDF
    'CLAHE': 'O(n + tÃ—256)',             # t: íƒ€ì¼ ìˆ˜ = (H/th)Ã—(W/tw)
    'Color HE (YUV)': 'O(3n + 256)',     # ìƒ‰ê³µê°„ ë³€í™˜ + Yì±„ë„ HE
    'Color HE (RGB)': 'O(3n + 3Ã—256)'   # 3ì±„ë„ ë…ë¦½ ì²˜ë¦¬
}

# 640x480 ì´ë¯¸ì§€ ê¸°ì¤€ ì—°ì‚°ëŸ‰
image_pixels = 640 * 480  # 307,200 í”½ì…€
tile_count_8x8 = (640//8) * (480//8)  # 6,000 íƒ€ì¼
```

#### Otsu Thresholding ë³µì¡ë„

```python
# ë°©ë²•ë³„ ì‹œê°„ ë³µì¡ë„
otsu_complexities = {
    'Global Otsu': 'O(n + 256Â²)',                    # íˆìŠ¤í† ê·¸ë¨ + 256íšŒ variance ê³„ì‚°
    'Block-based': 'O(n + bÃ—256Â²)',                  # b: ë¸”ë¡ ìˆ˜
    'Sliding Window': 'O(nÃ—w + wÃ—256Â²)',             # w: ìœˆë„ìš° ìˆ˜, ì¤‘ë³µ ê³„ì‚° í¬í•¨
    'Improved Overlapping': 'O(n + bÃ—4Ã—256Â²)',      # 4ë°° ê²¹ì¹¨ ë¸”ë¡ ì²˜ë¦¬
    'Interpolation-based': 'O(n + gÃ—256Â² + n)',     # g: ê·¸ë¦¬ë“œ ì  ìˆ˜, ë³´ê°„ ì²˜ë¦¬
}

# 640x480 ì´ë¯¸ì§€ ê¸°ì¤€
block_count_32x32 = (640//32) * (480//32)  # 300 ë¸”ë¡
window_count = ((640-32)//8 + 1) * ((480-32)//8 + 1)  # 4,617 ìœˆë„ìš°
```

### ì‹¤ì œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹

#### ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •

```python
# src/performance_benchmark.py êµ¬í˜„ ì˜ˆì‹œ
import time
import numpy as np
from typing import Dict, List

def benchmark_he_methods(image: np.ndarray, iterations: int = 10) -> Dict[str, float]:
    """íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ë°©ë²•ë³„ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •"""
    results = {}

    # Global HE
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = histogram_equalization_grayscale(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Global_HE'] = np.mean(times)

    # CLAHE 8x8
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = clahe_implementation(image, tile_size=(8, 8), show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['CLAHE_8x8'] = np.mean(times)

    return results

def benchmark_otsu_methods(image: np.ndarray, iterations: int = 10) -> Dict[str, float]:
    """Otsu ë°©ë²•ë³„ ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •"""
    results = {}

    # Global Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = global_otsu_thresholding(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Global_Otsu'] = np.mean(times)

    # Block-based Local Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = local_otsu_block_based(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Block_Otsu'] = np.mean(times)

    # Sliding Window Local Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = local_otsu_sliding_window(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Sliding_Otsu'] = np.mean(times)

    # ğŸ†• Improved Local Otsu
    times = []
    for _ in range(iterations):
        start = time.perf_counter()
        _ = local_otsu_improved_boundary(image, show_process=False)
        end = time.perf_counter()
        times.append(end - start)
    results['Improved_Otsu'] = np.mean(times)

    return results
```

#### OpenCV ëŒ€ë¹„ ì„±ëŠ¥ ë¹„êµ

```python
def compare_with_opencv(image: np.ndarray) -> Dict[str, Dict[str, float]]:
    """OpenCV ë‚´ì¥ í•¨ìˆ˜ì™€ ì„±ëŠ¥ ë¹„êµ"""
    import cv2

    # íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ë¹„êµ
    he_comparison = {}

    # Our implementation
    start = time.perf_counter()
    our_result = histogram_equalization_grayscale(image, show_process=False)
    our_time = time.perf_counter() - start

    # OpenCV implementation
    start = time.perf_counter()
    cv_result = cv2.equalizeHist(image)
    cv_time = time.perf_counter() - start

    he_comparison = {
        'our_implementation': our_time,
        'opencv': cv_time,
        'speed_ratio': our_time / cv_time,
        'result_difference': np.mean(np.abs(our_result[0] - cv_result))
    }

    # CLAHE ë¹„êµ
    clahe_comparison = {}

    # Our CLAHE
    start = time.perf_counter()
    our_clahe = clahe_implementation(image, show_process=False)
    our_time = time.perf_counter() - start

    # OpenCV CLAHE
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    start = time.perf_counter()
    cv_clahe = clahe.apply(image)
    cv_time = time.perf_counter() - start

    clahe_comparison = {
        'our_implementation': our_time,
        'opencv': cv_time,
        'speed_ratio': our_time / cv_time,
        'result_difference': np.mean(np.abs(our_clahe[0] - cv_clahe))
    }

    # AHE ë¹„êµ (OpenCVëŠ” ë‚´ì¥ AHE ì—†ìŒ, CLAHEë¡œ ê·¼ì‚¬)
    ahe_comparison = {}

    # Our AHE (clip_limit=999.0ìœ¼ë¡œ í´ë¦¬í•‘ ë¹„í™œì„±í™”)
    start = time.perf_counter()
    our_ahe = clahe_implementation(image, clip_limit=999.0, tile_size=(16, 16), show_process=False)
    our_time = time.perf_counter() - start

    ahe_comparison = {
        'our_implementation': our_time,
        'note': 'OpenCV has no direct AHE - CLAHE with high clip_limit used'
    }

    return {
        'histogram_equalization': he_comparison,
        'clahe': clahe_comparison,
        'ahe': ahe_comparison
    }
```

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¶„ì„

```python
import psutil
import os

def measure_memory_usage(func, *args, **kwargs):
    """í•¨ìˆ˜ ì‹¤í–‰ ì¤‘ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
    process = psutil.Process(os.getpid())

    # ì‹œì‘ ë©”ëª¨ë¦¬
    start_memory = process.memory_info().rss / 1024 / 1024  # MB

    # í•¨ìˆ˜ ì‹¤í–‰
    result = func(*args, **kwargs)

    # ì¢…ë£Œ ë©”ëª¨ë¦¬
    end_memory = process.memory_info().rss / 1024 / 1024  # MB

    return result, end_memory - start_memory

# ì‚¬ìš© ì˜ˆì‹œ
image = np.random.randint(0, 256, (480, 640), dtype=np.uint8)

# Global Otsu ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
_, global_memory = measure_memory_usage(global_otsu_thresholding, image, False)

# Sliding Window ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
_, sliding_memory = measure_memory_usage(local_otsu_sliding_window, image, False)

print(f"Global Otsu: {global_memory:.2f} MB")
print(f"Sliding Window: {sliding_memory:.2f} MB")
```

### ì •ëŸ‰ì  í’ˆì§ˆ í‰ê°€

#### íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” í’ˆì§ˆ ì§€í‘œ

```python
def evaluate_he_quality(original: np.ndarray, enhanced: np.ndarray) -> Dict[str, float]:
    """íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” í’ˆì§ˆ í‰ê°€"""

    # 1. ì—”íŠ¸ë¡œí”¼ ì¦ê°€ëŸ‰
    def calculate_entropy(image):
        hist, _ = compute_histogram(image)
        hist = hist / np.sum(hist)  # ì •ê·œí™”
        entropy = -np.sum(hist * np.log2(hist + 1e-10))
        return entropy

    original_entropy = calculate_entropy(original)
    enhanced_entropy = calculate_entropy(enhanced)

    # 2. ëŒ€ë¹„ ê°œì„ ë„ (í‘œì¤€í¸ì°¨ ì¦ê°€ìœ¨)
    contrast_improvement = np.std(enhanced) / np.std(original)

    # 3. íˆìŠ¤í† ê·¸ë¨ ê· ë“±ì„± (Chi-square test)
    enhanced_hist, _ = compute_histogram(enhanced)
    expected = np.full(256, enhanced.size / 256)  # ê· ë“±ë¶„í¬ ê¸°ëŒ“ê°’
    chi_square = np.sum((enhanced_hist - expected)**2 / expected)

    # 4. ë™ì  ë²”ìœ„ í™œìš©ë„
    dynamic_range = (np.max(enhanced) - np.min(enhanced)) / 255.0

    return {
        'entropy_gain': enhanced_entropy - original_entropy,
        'contrast_improvement': contrast_improvement,
        'uniformity_score': 1.0 / (1.0 + chi_square / 1000),  # ì •ê·œí™”
        'dynamic_range_usage': dynamic_range
    }
```

#### Otsu Thresholding í’ˆì§ˆ ì§€í‘œ

```python
def evaluate_otsu_quality(image: np.ndarray, binary_result: np.ndarray,
                         threshold_map: np.ndarray = None) -> Dict[str, float]:
    """Otsu Thresholding í’ˆì§ˆ í‰ê°€"""

    # 1. Inter-class variance (í´ìˆ˜ë¡ ì¢‹ìŒ)
    hist, _ = compute_histogram(image)
    if threshold_map is None:
        # Global threshold
        threshold = np.mean(threshold_map) if threshold_map is not None else 127
        _, calc_info = calculate_otsu_threshold(hist)
        inter_class_var = calc_info['max_inter_class_variance']
    else:
        # Local threshold - í‰ê·  inter-class variance
        inter_class_var = np.mean([calculate_inter_class_variance(image, t)
                                  for t in np.unique(threshold_map)])

    # 2. ì—°ê²°ì„± ì§€í‘œ (Connected Components)
    num_labels, labels = cv2.connectedComponents(binary_result.astype(np.uint8))
    connectivity_score = 1.0 / (1.0 + num_labels / 100)  # ì •ê·œí™”

    # 3. ì—£ì§€ ë³´ì¡´ ì •ë„
    def edge_preservation_score(original, binary):
        # Sobel edge detection
        edges_original = cv2.Sobel(original, cv2.CV_64F, 1, 1, ksize=3)
        edges_binary = cv2.Sobel(binary, cv2.CV_64F, 1, 1, ksize=3)

        # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        correlation = np.corrcoef(edges_original.flatten(),
                                edges_binary.flatten())[0,1]
        return max(0, correlation)  # ìŒìˆ˜ ì œê±°

    edge_score = edge_preservation_score(image, binary_result)

    # 4. ë…¸ì´ì¦ˆ ë ˆë²¨ (ì‘ì„ìˆ˜ë¡ ì¢‹ìŒ)
    noise_level = np.std(binary_result - cv2.medianBlur(binary_result, 5))

    return {
        'inter_class_variance': inter_class_var,
        'connectivity_score': connectivity_score,
        'edge_preservation': edge_score,
        'noise_level': noise_level
    }
```

---

## ì‹¤íŒ¨ ì‚¬ë¡€ ë° í•œê³„ ë¶„ì„

### íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì‹¤íŒ¨ ì‚¬ë¡€

#### 1. ê·¹ë‹¨ì  ì €ì¡°ë„ ì´ë¯¸ì§€

**ì‹¤íŒ¨ ì¡°ê±´:**
- ëŒ€ë¶€ë¶„ í”½ì…€ì´ 0-30 ë²”ìœ„ì— ì§‘ì¤‘ (85% ì´ìƒ)
- ìœ íš¨ ì •ë³´ê°€ ë§¤ìš° ì ì€ ê²½ìš°

**ì‹¤íŒ¨ ì›ì¸:**
```python
# ë¬¸ì œì  ë¶„ì„
hist, _ = compute_histogram(very_dark_image)
valid_info_ratio = np.sum(hist[30:]) / np.sum(hist)

if valid_info_ratio < 0.15:
    print("ê²½ê³ : ìœ íš¨ ì •ë³´ ë¶€ì¡±ìœ¼ë¡œ HE íš¨ê³¼ ì œí•œì ")

# CDF ë¶„ì„
cdf = calculate_cdf(hist)
steep_slope = np.max(np.diff(cdf[:50]))  # ì´ˆê¸° 50êµ¬ê°„ ê¸°ìš¸ê¸°

if steep_slope > 0.8:
    print("ê²½ê³ : ê¸‰ê²©í•œ ë§¤í•‘ìœ¼ë¡œ ì¸í•œ ê³„ë‹¨ í˜„ìƒ ë°œìƒ ê°€ëŠ¥")
```

**í•´ê²° ë°©ì•ˆ:**
- ê°ë§ˆ ë³´ì • ì „ì²˜ë¦¬ ì ìš©
- CLAHEì˜ clip_limit ì¡°ì • (0.5-1.0)
- ì ì‘ì  ì „ì²˜ë¦¬ ì ìš©

#### 2. í¬í™”ëœ ë°ì€ ì´ë¯¸ì§€

**ì‹¤íŒ¨ ì¡°ê±´:**
- ëŒ€ë¶€ë¶„ í”½ì…€ì´ 220-255 ë²”ìœ„ì— ì§‘ì¤‘
- ì˜¤ë²„ ìµìŠ¤í¬ì € ìƒíƒœ

**ë¬¸ì œì :**
```python
# í¬í™” ì˜ì—­ ë¶„ì„
saturated_ratio = np.sum(image >= 250) / image.size

if saturated_ratio > 0.3:
    print("ê²½ê³ : í¬í™” ì˜ì—­ ê³¼ë‹¤ë¡œ ë””í…Œì¼ ë³µì› ë¶ˆê°€")

# íˆìŠ¤í† ê·¸ë¨ ë¶„í¬ ë¶„ì„
hist, _ = compute_histogram(image)
high_intensity_ratio = np.sum(hist[200:]) / np.sum(hist)

if high_intensity_ratio > 0.7:
    print("ê²½ê³ : íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” íš¨ê³¼ ë¯¸ë¯¸")
```

#### 3. ì»¬ëŸ¬ ì´ë¯¸ì§€ì—ì„œ RGB ê°œë³„ ì²˜ë¦¬ ë¬¸ì œ

**ìƒ‰ìƒ ì™œê³¡ ì‚¬ë¡€:**
```python
# RGB ê°œë³„ ì²˜ë¦¬ ì‹œ ìƒ‰ìƒ ë³€í™” ì¸¡ì •
def measure_color_distortion(original_rgb, processed_rgb):
    # HSV ìƒ‰ê³µê°„ì—ì„œ Hue ë³€í™”ëŸ‰ ì¸¡ì •
    original_hsv = cv2.cvtColor(original_rgb, cv2.COLOR_RGB2HSV)
    processed_hsv = cv2.cvtColor(processed_rgb, cv2.COLOR_RGB2HSV)

    hue_diff = np.abs(original_hsv[:,:,0].astype(float) -
                     processed_hsv[:,:,0].astype(float))

    # HueëŠ” ìˆœí™˜ì ì´ë¯€ë¡œ 180ë„ ì´ìƒ ì°¨ì´ëŠ” ë³´ì •
    hue_diff = np.minimum(hue_diff, 360 - hue_diff)

    mean_hue_shift = np.mean(hue_diff)
    return mean_hue_shift

# YUV vs RGB ì²˜ë¦¬ ë¹„êµ
yuv_result, _ = histogram_equalization_color(image, method='yuv')
rgb_result, _ = histogram_equalization_color(image, method='rgb')

yuv_distortion = measure_color_distortion(image, yuv_result)
rgb_distortion = measure_color_distortion(image, rgb_result)

print(f"YUV ë°©ë²• ìƒ‰ìƒ ë³€í™”: {yuv_distortion:.2f}ë„")
print(f"RGB ë°©ë²• ìƒ‰ìƒ ë³€í™”: {rgb_distortion:.2f}ë„")
```

### Otsu Thresholding ì‹¤íŒ¨ ì‚¬ë¡€

#### 1. ë‹¨ì¼ ëª¨ë“œ íˆìŠ¤í† ê·¸ë¨

**ì‹¤íŒ¨ ì¡°ê±´:**
- ì „ê²½ê³¼ ë°°ê²½ì˜ ë¶„ë¦¬ê°€ ë¶ˆëª…í™•
- íˆìŠ¤í† ê·¸ë¨ì´ ë‹¨ë´‰ ë¶„í¬

**ë¶„ì„ ë°©ë²•:**
```python
def analyze_histogram_modality(image):
    """íˆìŠ¤í† ê·¸ë¨ ëª¨ë“œ ë¶„ì„"""
    hist, _ = compute_histogram(image)

    # ìŠ¤ë¬´ë”©ëœ íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ í”¼í¬ ì°¾ê¸°
    from scipy.signal import find_peaks
    smoothed_hist = np.convolve(hist, np.ones(5)/5, mode='same')
    peaks, _ = find_peaks(smoothed_hist, height=np.max(smoothed_hist)*0.1)

    if len(peaks) < 2:
        print("ê²½ê³ : ë‹¨ì¼ ëª¨ë“œ íˆìŠ¤í† ê·¸ë¨ - Otsu ë°©ë²• ë¶€ì í•©")
        return False

    # ë‘ ì£¼ìš” í”¼í¬ ê°„ valley ê¹Šì´ í™•ì¸
    valley_depth = np.min(smoothed_hist[peaks[0]:peaks[1]])
    peak_height = np.mean([smoothed_hist[peaks[0]], smoothed_hist[peaks[1]]])

    if valley_depth / peak_height > 0.5:
        print("ê²½ê³ : ì–•ì€ valley - ë¶„ë¦¬ ì„±ëŠ¥ ì œí•œì ")
        return False

    return True
```

#### 2. ê·¹ë‹¨ì  ë¶ˆê· ë“± ì¡°ëª…

**ì‹¤íŒ¨ ì¡°ê±´:**
- í•œìª½ ëì´ ë§¤ìš° ë°ê³  ë‹¤ë¥¸ ìª½ì´ ë§¤ìš° ì–´ë‘ì›€
- ì ì§„ì  ë³€í™”ë¡œ ì¸í•œ ì§€ì—­ë³„ ìµœì  ì„ê³„ê°’ í° ì°¨ì´

**ë¬¸ì œì  ë¶„ì„:**
```python
def analyze_illumination_gradient(image):
    """ì¡°ëª… ê¸°ìš¸ê¸° ë¶„ì„"""
    # ì´ë¯¸ì§€ë¥¼ ê²©ìë¡œ ë‚˜ëˆ„ì–´ í‰ê·  ë°ê¸° ë¶„ì„
    h, w = image.shape
    grid_h, grid_w = h//4, w//4

    brightness_map = np.zeros((4, 4))
    for i in range(4):
        for j in range(4):
            region = image[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]
            brightness_map[i, j] = np.mean(region)

    # ìµœëŒ€ ë°ê¸° ì°¨ì´ ê³„ì‚°
    max_diff = np.max(brightness_map) - np.min(brightness_map)

    if max_diff > 100:
        print(f"ê²½ê³ : ì¡°ëª… ë¶ˆê· ë“± ì‹¬ê° (ì°¨ì´: {max_diff:.1f})")
        print("ê¶Œì¥: Local Otsu ë°©ë²• ì‚¬ìš©")
        return True

    return False
```

#### 3. Block-basedì˜ ê²½ê³„ ë¶ˆì—°ì†ì„±

**ë¬¸ì œ ì‹œê°í™”:**
```python
def visualize_block_discontinuity(image, block_size=(32, 32)):
    """ë¸”ë¡ ê²½ê³„ ë¶ˆì—°ì†ì„± ì‹œê°í™”"""
    # Block-based ì²˜ë¦¬
    result, info = local_otsu_block_based(image, block_size=block_size, show_process=False)
    threshold_map = info['threshold_map']

    # ì„ê³„ê°’ ì°¨ì´ ë§µ ìƒì„±
    h, w = threshold_map.shape
    bh, bw = block_size

    diff_map = np.zeros_like(threshold_map)

    # ë¸”ë¡ ê²½ê³„ì—ì„œ ì„ê³„ê°’ ì°¨ì´ ê³„ì‚°
    for i in range(bh, h, bh):
        diff_map[i-1:i+1, :] = np.abs(threshold_map[i-2, :] - threshold_map[i+1, :])

    for j in range(bw, w, bw):
        diff_map[:, j-1:j+1] = np.abs(threshold_map[:, j-2] - threshold_map[:, j+1])

    # ë¶ˆì—°ì†ì„± ì‹¬ê°ë„ í‰ê°€
    discontinuity_score = np.mean(diff_map[diff_map > 0])

    if discontinuity_score > 30:
        print(f"ê²½ê³ : ë¸”ë¡ ê²½ê³„ ë¶ˆì—°ì†ì„± ì‹¬ê° (ì ìˆ˜: {discontinuity_score:.1f})")
        print("ê¶Œì¥: Sliding Window ë°©ë²• ë˜ëŠ” ë¸”ë¡ í¬ê¸° ì¶•ì†Œ")

    return diff_map, discontinuity_score
```

#### ğŸ†• ë¸”ë¡ ê²½ê³„ ì•„í‹°íŒ©íŠ¸ í•´ê²°ì±…

**ë¬¸ì œ í•´ê²°:**
ê¸°ì¡´ Block-based ë°©ë²•ì˜ ê·¼ë³¸ì  ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ê°œì„ ëœ ë°©ë²•ì„ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤.

```python
def analyze_boundary_improvement():
    """ê²½ê³„ ì•„í‹°íŒ©íŠ¸ ê°œì„  íš¨ê³¼ ì¸¡ì •"""

    # ê¸°ì¡´ ë°©ë²• vs ê°œì„ ëœ ë°©ë²• ë¹„êµ
    original_result, original_info = local_otsu_block_based(image, show_process=False)
    improved_result, improved_info = local_otsu_improved_boundary(image, show_process=False)

    # ë¸”ë¡ ê²½ê³„ ë¶ˆì—°ì†ì„± ì¸¡ì •
    def measure_boundary_discontinuity(threshold_map, block_size=32):
        height, width = threshold_map.shape
        diffs = []

        # ìˆ˜ì§ ê²½ê³„ ë¶ˆì—°ì†ì„±
        for x in range(block_size, width, block_size):
            if x < width - 1:
                diff = np.abs(threshold_map[:, x] - threshold_map[:, x-1])
                diffs.extend(diff)

        return np.mean(diffs)

    original_discontinuity = measure_boundary_discontinuity(original_info['threshold_map'])
    improved_discontinuity = measure_boundary_discontinuity(improved_info['threshold_map'])

    improvement_rate = (1 - improved_discontinuity/original_discontinuity) * 100

    print(f"ê²½ê³„ ë¶ˆì—°ì†ì„± ê°œì„ :")
    print(f"  ê¸°ì¡´ ë°©ë²•: {original_discontinuity:.2f}")
    print(f"  ê°œì„  ë°©ë²•: {improved_discontinuity:.2f}")
    print(f"  ê°œì„ ë¥ : {improvement_rate:.1f}%")

    return improvement_rate

# ì‹¤ì œ ì¸¡ì • ê²°ê³¼: 96.3% ê°œì„  ë‹¬ì„±
```

**í•µì‹¬ ê°œì„ ì‚¬í•­:**
- **ê²¹ì¹˜ëŠ” ë¸”ë¡ ì²˜ë¦¬**: 50% ê²¹ì¹¨ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ì „í™˜
- **ê°€ì¤‘ ë¸”ë Œë”©**: ê±°ë¦¬ ê¸°ë°˜ ê°€ì¤‘ì¹˜ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ê²°í•©
- **í…ìŠ¤íŠ¸ ì¹œí™”ì  í›„ì²˜ë¦¬**: ë¬¸ì„œ ì´ë¯¸ì§€ì— ìµœì í™”ëœ ì„¤ì •

### í•œê³„ì  ë° ê°œì„  ë°©í–¥

#### 1. ì‹¤ì‹œê°„ ì²˜ë¦¬ í•œê³„

**í˜„ì¬ í•œê³„:**
- Sliding Window ë°©ë²•ì˜ ë†’ì€ ê³„ì‚° ë³µì¡ë„
- 640x480 ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œê°„: 0.5-2ì´ˆ

**ê°œì„  ë°©ì•ˆ:**
```python
# ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”
import multiprocessing as mp
from concurrent.futures import ThreadPoolExecutor

def parallel_sliding_window(image, window_size, stride, num_workers=4):
    """ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ì´ìš©í•œ Sliding Window ìµœì í™”"""
    h, w = image.shape
    wh, ww = window_size

    # ì‘ì—… ë¶„í• 
    work_regions = []
    region_h = h // num_workers

    for i in range(num_workers):
        start_row = i * region_h
        end_row = (i + 1) * region_h if i < num_workers - 1 else h
        work_regions.append((start_row, end_row))

    # ë³‘ë ¬ ì‹¤í–‰
    with ThreadPoolExecutor(max_workers=num_workers) as executor:
        futures = []
        for start_row, end_row in work_regions:
            region = image[start_row:end_row, :]
            future = executor.submit(process_sliding_window_region,
                                   region, window_size, stride)
            futures.append(future)

        results = [future.result() for future in futures]

    # ê²°ê³¼ ë³‘í•©
    return merge_results(results)
```

#### 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”

**í˜„ì¬ ë¬¸ì œ:**
- Sliding Windowì—ì„œ ì¤‘ë³µ íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
- ì„ê³„ê°’ ë§µ ì €ì¥ìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€

**ê°œì„  ë°©ì•ˆ:**
```python
def memory_efficient_sliding_window(image, window_size, stride):
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ Sliding Window êµ¬í˜„"""
    h, w = image.shape
    wh, ww = window_size

    # ê²°ê³¼ ì´ë¯¸ì§€ë§Œ ì €ì¥, ì„ê³„ê°’ ë§µ ìƒëµ
    result = np.zeros_like(image)

    # ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
    for i in range(0, h - wh + 1, stride):
        for j in range(0, w - ww + 1, stride):
            # ìœˆë„ìš° ì˜ì—­ ì²˜ë¦¬
            window = image[i:i+wh, j:j+ww]
            threshold = calculate_local_threshold(window)

            # ê²°ê³¼ì— ì§ì ‘ ì ìš© (ì¤‘ê°„ ì €ì¥ì†Œ ë¶ˆí•„ìš”)
            center_i = i + wh//2
            center_j = j + ww//2
            result[center_i-stride//2:center_i+stride//2,
                   center_j-stride//2:center_j+stride//2] = \
                apply_threshold(image[center_i-stride//2:center_i+stride//2,
                                    center_j-stride//2:center_j+stride//2],
                              threshold)

    return result
```

---

## ì‚°ì—… ì‘ìš© ì‚¬ë¡€

### ë¬¸ì„œ ë””ì§€í„¸í™” ì‹œìŠ¤í…œ

#### ì‘ìš© ë¶„ì•¼
- ë„ì„œê´€ ê³ ë¬¸ì„œ ë””ì§€í„¸í™”
- ë²•ë¬´ ë¬¸ì„œ ì•„ì¹´ì´ë¹™
- ì˜ë£Œ ì°¨íŠ¸ ì „ì‚°í™”

#### ê¸°ìˆ ì  ìš”êµ¬ì‚¬í•­
```python
class DocumentDigitizer:
    """ë¬¸ì„œ ë””ì§€í„¸í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.he_config = {
            'method': 'yuv',
            'clahe_params': {'clip_limit': 1.5, 'tile_size': (16, 16)}
        }
        self.otsu_config = {
            'method': 'sliding_window',
            'window_size': (24, 24),
            'stride': 6
        }

    def process_document(self, image_path: str) -> Dict[str, np.ndarray]:
        """ë¬¸ì„œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""
        # 1. ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
        image = self.load_and_preprocess(image_path)

        # 2. ì¡°ëª… ë³´ì • (íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
        enhanced_image = self.enhance_illumination(image)

        # 3. ì´ì§„í™” (Otsu Thresholding)
        binary_image = self.binarize_document(enhanced_image)

        # 4. í›„ì²˜ë¦¬ (ë…¸ì´ì¦ˆ ì œê±°, ê¸°ìš¸ê¸° ë³´ì •)
        final_image = self.post_process(binary_image)

        return {
            'original': image,
            'enhanced': enhanced_image,
            'binary': binary_image,
            'final': final_image
        }

    def enhance_illumination(self, image: np.ndarray) -> np.ndarray:
        """ì¡°ëª… ë¶ˆê· ë“± ë³´ì •"""
        # ì¡°ëª… ë¶ˆê· ë“± ì •ë„ ìë™ ê°ì§€
        illumination_variance = self.analyze_illumination_uniformity(image)

        if illumination_variance > 50:
            # ì‹¬í•œ ë¶ˆê· ë“± â†’ CLAHE ì ìš©
            result, _ = clahe_implementation(
                image,
                clip_limit=self.he_config['clahe_params']['clip_limit'],
                tile_size=self.he_config['clahe_params']['tile_size'],
                show_process=False
            )
        else:
            # ê²½ë¯¸í•œ ë¶ˆê· ë“± â†’ ì¼ë°˜ HE ì ìš©
            result, _ = histogram_equalization_grayscale(image, show_process=False)

        return result

    def binarize_document(self, image: np.ndarray) -> np.ndarray:
        """ë¬¸ì„œ ì´ì§„í™”"""
        # íˆìŠ¤í† ê·¸ë¨ ëª¨ë“œ ë¶„ì„ìœ¼ë¡œ ë°©ë²• ì„ íƒ
        is_bimodal = self.analyze_histogram_modality(image)

        if is_bimodal:
            # ëª…í™•í•œ ì´ì¤‘ ëª¨ë“œ â†’ Global Otsu
            result, _ = global_otsu_thresholding(image, show_process=False)
        else:
            # ë³µì¡í•œ ë¶„í¬ â†’ Local Otsu
            result, _ = local_otsu_sliding_window(
                image,
                window_size=self.otsu_config['window_size'],
                stride=self.otsu_config['stride'],
                show_process=False
            )

        return result
```

#### ì„±ëŠ¥ ì§€í‘œ
- ì²˜ë¦¬ ì†ë„: 640x480 ë¬¸ì„œë‹¹ 2-5ì´ˆ
- OCR ì •í™•ë„ í–¥ìƒ: 15-25%
- íŒŒì¼ í¬ê¸° ê°ì†Œ: 40-60% (ì´ì§„í™” íš¨ê³¼)

### ì˜ë£Œ ì˜ìƒ ì²˜ë¦¬

#### ì‘ìš© ë¶„ì•¼
- X-ray ì´ë¯¸ì§€ ëŒ€ë¹„ ê°œì„ 
- ì´ˆìŒíŒŒ ì˜ìƒ ì„ ëª…ë„ í–¥ìƒ
- ë‚´ì‹œê²½ ì˜ìƒ ì „ì²˜ë¦¬

#### X-ray ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ
```python
class MedicalImageProcessor:
    """ì˜ë£Œ ì˜ìƒ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.xray_config = {
            'clahe_clip_limit': 3.0,  # ì˜ë£Œ ì˜ìƒì€ ë†’ì€ ëŒ€ë¹„ í•„ìš”
            'tile_size': (8, 8),
            'gamma_correction': 0.8   # ê°ë§ˆ ë³´ì •ìœ¼ë¡œ ì¤‘ê°„í†¤ ê°•ì¡°
        }

    def enhance_xray(self, xray_image: np.ndarray) -> Dict[str, np.ndarray]:
        """X-ray ì˜ìƒ ëŒ€ë¹„ ê°œì„ """
        # 1. ê°ë§ˆ ë³´ì •ìœ¼ë¡œ ì¤‘ê°„í†¤ ì˜ì—­ ê°•ì¡°
        gamma_corrected = self.apply_gamma_correction(
            xray_image,
            gamma=self.xray_config['gamma_correction']
        )

        # 2. CLAHEë¡œ ì§€ì—­ì  ëŒ€ë¹„ ê°œì„ 
        clahe_enhanced, _ = clahe_implementation(
            gamma_corrected,
            clip_limit=self.xray_config['clahe_clip_limit'],
            tile_size=self.xray_config['tile_size'],
            show_process=False
        )

        # 3. ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ ìœ„í•œ ì ì‘ì  í•„í„°ë§
        denoised = self.adaptive_denoising(clahe_enhanced)

        return {
            'original': xray_image,
            'gamma_corrected': gamma_corrected,
            'clahe_enhanced': clahe_enhanced,
            'final': denoised
        }

    def apply_gamma_correction(self, image: np.ndarray, gamma: float) -> np.ndarray:
        """ê°ë§ˆ ë³´ì • ì ìš©"""
        # ë£©ì—… í…Œì´ë¸” ìƒì„±
        inv_gamma = 1.0 / gamma
        lut = np.array([((i / 255.0) ** inv_gamma) * 255 for i in range(256)]).astype(np.uint8)

        # ë£©ì—… í…Œì´ë¸” ì ìš©
        return lut[image]
```

### ë³´ì•ˆ ê°ì‹œ ì‹œìŠ¤í…œ

#### ì‘ìš© ë¶„ì•¼
- ì•¼ê°„ ê°ì‹œ ì¹´ë©”ë¼ ì˜ìƒ ê°œì„ 
- ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹ ì „ì²˜ë¦¬
- ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ ì „ì²˜ë¦¬

#### ì‹¤ì‹œê°„ ì˜ìƒ ì²˜ë¦¬ ì‹œìŠ¤í…œ
```python
class SecurityVisionSystem:
    """ë³´ì•ˆ ê°ì‹œ ì˜ìƒ ì²˜ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.day_config = {
            'he_method': 'global',
            'otsu_method': 'block_based'
        }
        self.night_config = {
            'he_method': 'clahe',
            'clahe_params': {'clip_limit': 4.0, 'tile_size': (16, 16)},
            'otsu_method': 'sliding_window'
        }

    def process_surveillance_frame(self, frame: np.ndarray,
                                 is_night_mode: bool = False) -> Dict[str, np.ndarray]:
        """ê°ì‹œ ì˜ìƒ í”„ë ˆì„ ì²˜ë¦¬"""
        config = self.night_config if is_night_mode else self.day_config

        # 1. ì¡°ëª… ì¡°ê±´ì— ë”°ë¥¸ ì ì‘ì  ëŒ€ë¹„ ê°œì„ 
        if config['he_method'] == 'clahe':
            enhanced, _ = clahe_implementation(
                frame,
                clip_limit=config['clahe_params']['clip_limit'],
                tile_size=config['clahe_params']['tile_size'],
                show_process=False
            )
        else:
            enhanced, _ = histogram_equalization_grayscale(frame, show_process=False)

        # 2. ê°ì²´ ë¶„í• ì„ ìœ„í•œ ì´ì§„í™”
        if config['otsu_method'] == 'sliding_window':
            binary, _ = local_otsu_sliding_window(enhanced, show_process=False)
        else:
            binary, _ = local_otsu_block_based(enhanced, show_process=False)

        # 3. ëª¨ì…˜ ê°ì§€ìš© ì „ì²˜ë¦¬
        motion_ready = self.prepare_for_motion_detection(enhanced)

        return {
            'enhanced': enhanced,
            'binary': binary,
            'motion_ready': motion_ready
        }

    def prepare_for_motion_detection(self, image: np.ndarray) -> np.ndarray:
        """ëª¨ì…˜ ê°ì§€ë¥¼ ìœ„í•œ ì „ì²˜ë¦¬"""
        # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ê°ì†Œ
        blurred = cv2.GaussianBlur(image, (5, 5), 0)

        # ì ì‘ì  ì„ê³„ê°’ìœ¼ë¡œ ë°°ê²½ ë¶„ë¦¬
        adaptive_thresh = cv2.adaptiveThreshold(
            blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY, 11, 2
        )

        return adaptive_thresh
```

### ì‚°ì—… ìë™í™” ë¹„ì „ ì‹œìŠ¤í…œ

#### ì‘ìš© ë¶„ì•¼
- ì œí’ˆ í’ˆì§ˆ ê²€ì‚¬
- ë°”ì½”ë“œ/QRì½”ë“œ ì¸ì‹
- ë¡œë´‡ ë¹„ì „ ì‹œìŠ¤í…œ

#### ì œí’ˆ ê²€ì‚¬ ì‹œìŠ¤í…œ
```python
class IndustrialVisionInspector:
    """ì‚°ì—…ìš© ë¹„ì „ ê²€ì‚¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.inspection_config = {
            'he_clip_limit': 2.5,
            'tile_size': (12, 12),
            'window_size': (20, 20),
            'stride': 5
        }

    def inspect_product(self, product_image: np.ndarray) -> Dict[str, any]:
        """ì œí’ˆ ê²€ì‚¬ ìˆ˜í–‰"""
        # 1. ì¡°ëª… ì •ê·œí™”
        normalized = self.normalize_illumination(product_image)

        # 2. ê²°í•¨ ê°ì§€ë¥¼ ìœ„í•œ ì´ì§„í™”
        defect_map = self.detect_defects(normalized)

        # 3. ì¹˜ìˆ˜ ì¸¡ì •ì„ ìœ„í•œ ì—£ì§€ ê²€ì¶œ
        edges = self.extract_measurement_edges(normalized)

        # 4. ê²€ì‚¬ ê²°ê³¼ ë¶„ì„
        inspection_result = self.analyze_inspection_results(defect_map, edges)

        return {
            'normalized_image': normalized,
            'defect_map': defect_map,
            'measurement_edges': edges,
            'pass_fail': inspection_result['pass_fail'],
            'defect_count': inspection_result['defect_count'],
            'measurements': inspection_result['measurements']
        }

    def normalize_illumination(self, image: np.ndarray) -> np.ndarray:
        """ì¡°ëª… ì •ê·œí™” (ê³µì¥ í™˜ê²½ì˜ ë¶ˆê· ë“± ì¡°ëª… ë³´ì •)"""
        # CLAHEë¡œ ì§€ì—­ì  ì¡°ëª… ë³€í™” ë³´ì •
        normalized, _ = clahe_implementation(
            image,
            clip_limit=self.inspection_config['he_clip_limit'],
            tile_size=self.inspection_config['tile_size'],
            show_process=False
        )

        return normalized

    def detect_defects(self, image: np.ndarray) -> np.ndarray:
        """ê²°í•¨ ê°ì§€ìš© ì´ì§„í™”"""
        # ë†’ì€ í•´ìƒë„ì˜ Local Otsuë¡œ ë¯¸ì„¸ ê²°í•¨ ê°ì§€
        defect_binary, _ = local_otsu_sliding_window(
            image,
            window_size=self.inspection_config['window_size'],
            stride=self.inspection_config['stride'],
            show_process=False
        )

        # í˜•íƒœí•™ì  ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))
        cleaned = cv2.morphologyEx(defect_binary, cv2.MORPH_OPEN, kernel)

        return cleaned
```

### í¬íŒ… ë° í™•ì¥ ê°€ëŠ¥ì„±

#### C++ í¬íŒ… ê³ ë ¤ì‚¬í•­
```cpp
// C++17 êµ¬í˜„ ì˜ˆì‹œ (í•µì‹¬ ë¶€ë¶„)
class HistogramEqualizer {
private:
    std::vector<uint32_t> histogram_;
    std::vector<double> cdf_;

public:
    cv::Mat equalizeHistogram(const cv::Mat& input) {
        // íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
        calculateHistogram(input);

        // CDF ê³„ì‚°
        calculateCDF();

        // ë£©ì—… í…Œì´ë¸” ìƒì„± ë° ì ìš©
        std::vector<uint8_t> lut(256);
        for (int i = 0; i < 256; ++i) {
            lut[i] = static_cast<uint8_t>(255.0 * cdf_[i]);
        }

        cv::Mat output;
        cv::LUT(input, cv::Mat(lut), output);

        return output;
    }

private:
    void calculateHistogram(const cv::Mat& image) {
        histogram_.assign(256, 0);

        // OpenMPë¥¼ ì´ìš©í•œ ë³‘ë ¬í™”
        #pragma omp parallel for
        for (int i = 0; i < image.rows; ++i) {
            const uint8_t* row = image.ptr<uint8_t>(i);
            for (int j = 0; j < image.cols; ++j) {
                #pragma omp atomic
                ++histogram_[row[j]];
            }
        }
    }
};
```

#### CUDA GPU ê°€ì† ê°€ëŠ¥ì„±
```cuda
// CUDA ì»¤ë„ ì˜ˆì‹œ
__global__ void histogramEqualizationKernel(
    const uint8_t* input,
    uint8_t* output,
    const uint8_t* lut,
    int width,
    int height) {

    int idx = blockIdx.x * blockDim.x + threadIdx.x;
    int total_pixels = width * height;

    if (idx < total_pixels) {
        output[idx] = lut[input[idx]];
    }
}

// í˜¸ìŠ¤íŠ¸ ì½”ë“œ
void cudaHistogramEqualization(
    const cv::Mat& input,
    cv::Mat& output) {

    // GPU ë©”ëª¨ë¦¬ í• ë‹¹
    uint8_t* d_input, * d_output, * d_lut;

    // íˆìŠ¤í† ê·¸ë¨ ê³„ì‚° (GPU)
    computeHistogramCuda(d_input, d_histogram);

    // CDF ê³„ì‚° (GPU)
    computeCDFCuda(d_histogram, d_cdf);

    // ë£©ì—… í…Œì´ë¸” ìƒì„± (GPU)
    generateLUTCuda(d_cdf, d_lut);

    // ì´ë¯¸ì§€ ë³€í™˜ (GPU)
    dim3 block(256);
    dim3 grid((input.total() + block.x - 1) / block.x);

    histogramEqualizationKernel<<<grid, block>>>(
        d_input, d_output, d_lut,
        input.cols, input.rows
    );

    // ê²°ê³¼ ë³µì‚¬
    cudaMemcpy(output.data, d_output,
               input.total(), cudaMemcpyDeviceToHost);
}
```

